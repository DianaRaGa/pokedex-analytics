{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b98d4e94-3813-482d-97ad-8511d11f9a44",
   "metadata": {},
   "source": [
    "# **Pok√©mon Data Scraper**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36bb6cc-4dcd-4752-9a72-54668b7c5a13",
   "metadata": {},
   "source": [
    "üìå **How to Use This Notebook:**\n",
    "\n",
    "This notebook is designed to scrape and organize Pok√©mon data from the pok√©mon database website into a structured format, including stats, generation, and their artwork links.\n",
    "It‚Äôs structured into the following steps:\n",
    "\n",
    "**1. Import Libraries:** Loads the necessary tools for scraping and working with data.\n",
    "\n",
    "**2. Ignore SSL Errors:** Bypasses certificate warnings that could interrupt scraping.\n",
    "\n",
    "**3. Access the URL and Extract Table Rows:** Connects to the Pok√©mon database and pulls HTML rows.\n",
    "\n",
    "**4. Extract Values (excluding special Pok√©mon):** Filters out alternate forms, mega evolutions, etc., to keep only standard entries.\n",
    "\n",
    "**5. Save DataFrame with Basic Info ‚úÖ:** ‚ö†Ô∏è No need to re-run this step if you've already saved the CSV ‚Äî it will overwrite your existing file!\n",
    "\n",
    "**6. Add Generation & Image URL:** Visits individual Pok√©mon pages to extract generation and official image links.\n",
    "\n",
    "üí° **Tips:**\n",
    "\n",
    "Don‚Äôt want to scrape everything at once?\n",
    "Run steps 1 to 4 to get general stats only (much faster).\n",
    "\n",
    "Want to finish collecting image links in bulk?\n",
    "You can pick up from Step 6: the code checks for missing entries and continues from where it left off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa1bff3-2f7d-4f19-b25e-b3d9377a40c0",
   "metadata": {},
   "source": [
    "**1. Importing all of the libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76c9ed9a-a5bc-4cc9-9958-c8e112af01ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "import ssl\n",
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84677604-5260-4939-b93e-37a9a0aa7ef0",
   "metadata": {},
   "source": [
    "**2. Ignoring SSL certificate errors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c409c060-5c62-493d-841d-21118f5a3d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac886187-65dd-4947-839d-6bd37be820bf",
   "metadata": {},
   "source": [
    "**3. Accesing the URL  and extracting the rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1b5b58c-d9b9-4b7e-a8fd-58536f07c295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tr>\n",
      "<td class=\"cell-num cell-fixed\" data-sort-value=\"1\"><picture class=\"infocard-cell-img\">\n",
      "<source height=\"56\" srcset=\"https://img.pokemondb.net/sprites/scarlet-violet/icon/avif/bulbasaur.avif\" type=\"image/avif\" width=\"60\"/>\n",
      "<img alt=\"Bulbasaur\" class=\"img-fixed icon-pkmn\" height=\"56\" loading=\"lazy\" src=\"https://img.pokemondb.net/sprites/scarlet-violet/icon/bulbasaur.png\" width=\"60\"/>\n",
      "</picture><span class=\"infocard-cell-data\">0001</span></td> <td class=\"cell-name\"><a class=\"ent-name\" href=\"/pokedex/bulbasaur\" title=\"View Pokedex for #0001 Bulbasaur\">Bulbasaur</a></td><td class=\"cell-icon\"><a class=\"type-icon type-grass\" href=\"/type/grass\">Grass</a><br/> <a class=\"type-icon type-poison\" href=\"/type/poison\">Poison</a></td>\n",
      "<td class=\"cell-num cell-total\">318</td>\n",
      "<td class=\"cell-num\">45</td>\n",
      "<td class=\"cell-num\">49</td>\n",
      "<td class=\"cell-num\">49</td>\n",
      "<td class=\"cell-num\">65</td>\n",
      "<td class=\"cell-num\">65</td>\n",
      "<td class=\"cell-num\">45</td>\n",
      "</tr>]\n"
     ]
    }
   ],
   "source": [
    "url = 'https://pokemondb.net/pokedex/all'\n",
    "req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "html = urlopen(req).read()\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "rows = soup.find_all('tr')\n",
    "print(rows[1:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29a8b13-37c5-4716-a12f-3c4f9afde7e3",
   "metadata": {},
   "source": [
    "**4. Extracting the values from the table (excluding especial pokemons)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42d9804e-7f30-4eea-bfef-9d7acc5cf002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('0001', 'Bulbasaur', 'Grass', 'Poison', '318', '45', '49', '49', '65', '65', '45')]\n",
      "[('0001', 'Bulbasaur', 'https://pokemondb.net/pokedex/bulbasaur')]\n"
     ]
    }
   ],
   "source": [
    "pokemon_data = []\n",
    "dex_links = []\n",
    "numbers = set()\n",
    "\n",
    "for row in rows[1:]: #This is to skip the header\n",
    "    line = row.find_all('td')\n",
    "\n",
    "    #First: Getting the dex number from the pokedex table to omitting extra forms\n",
    "    dex_number = line[0].find('span', class_='infocard-cell-data').text.strip()\n",
    "\n",
    "    if dex_number not in numbers:\n",
    "        numbers.add(dex_number) #This ensures to only have the first pokemon for each dex number (omitting extra frorms)\n",
    "        \n",
    "        #Link to each pokemon stats\n",
    "        position_href = line[1].find('a', class_=\"ent-name\")\n",
    "        relative_link = position_href['href']\n",
    "        full_link = \"https://pokemondb.net\" + relative_link    \n",
    "        \n",
    "        #Name of the pokemon (set to add special cases in the future)\n",
    "        img_tag = line[0].find('img', class_='img-fixed icon-pkmn') #This gets the image tab where the real name for special pokemons is stored\n",
    "        name = img_tag['alt' ]#Brings the real neame for special cases \n",
    "\n",
    "        #Types of the pokemon separating for 1 or 2 cases\n",
    "        types = [t.text for t in line[2].find_all('a')] \n",
    "        #This part separates the 2 types for a clean transition to the database\n",
    "        if len(types) == 2:\n",
    "            type_1 = types[0]\n",
    "            type_2 = types[1]\n",
    "        else:\n",
    "            type_1 = types[0]\n",
    "            type_2 = ''  \n",
    "\n",
    "        #Data from the stats\n",
    "        total = line[3].text.strip()\n",
    "        HP = line[4].text.strip()\n",
    "        Attack = line[5].text.strip()\n",
    "        Defense = line[6].text.strip()\n",
    "        Sp_Atk = line[7].text.strip()\n",
    "        Sp_Def = line[8].text.strip()\n",
    "        Speed = line[9].text.strip()\n",
    "\n",
    "        #Appending the data in a corresponding list\n",
    "        dex_links.append((dex_number, name, full_link)) #To not have the links in the main data set\n",
    "        pokemon_data.append((dex_number, name, type_1, type_2, total, HP, Attack, Defense, Sp_Atk, Sp_Def, Speed)) #Appending the data\n",
    "        \n",
    "    else:\n",
    "        continue\n",
    "\n",
    "print(pokemon_data[:1])\n",
    "print(dex_links[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae44deb7-2f46-48b5-b5f7-0d97875aaede",
   "metadata": {},
   "source": [
    "**5. Saving the scraped data in a DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af77b9c4-4e7f-44e4-8e61-d89290784266",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Data Frame to add data easier\n",
    "df_poke = pd.DataFrame(pokemon_data, columns=['Dex', 'Name', 'Type 1', 'Type 2', 'Total', 'HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed'])\n",
    "df_links = pd.DataFrame(dex_links,columns=['Dex', 'Name', 'poke_links'])\n",
    "\n",
    "df_links['Generation'] = 'N/A' # To store image URLs in the dataframe\n",
    "df_links['Image URL'] = 'N/A' # To store generation info in the dataframe\n",
    "\n",
    "#Saving the data frames as CSV for reusability\n",
    "file_path_links = os.path.join('..', 'Data', 'poke_links.csv') #The '..' (2 dots) goes one folder up\n",
    "df_links.to_csv(file_path_links, index=False)\n",
    "\n",
    "file_path_poke = os.path.join('..', 'Data', 'poke_data.csv') #The '..' (2 dots) goes one folder up\n",
    "df_poke.to_csv(file_path_poke, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2f617d-bc4d-49e2-864a-5b549dee74d6",
   "metadata": {},
   "source": [
    "**6. Adding the image URL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "376195d0-4227-4975-9066-fe0878187331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Found 0 Pok√©mon entries with missing data.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "How many would you like to scrape (max number 0)? 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Invalid number, exiting.\n"
     ]
    }
   ],
   "source": [
    "#Loading the CSV as the new DataFrame\n",
    "file_path = os.path.join('..', 'Data', 'poke_links.csv') #The '..' (2 dots) goes one folder up\n",
    "df_links = pd.read_csv(file_path)\n",
    "\n",
    "# Replace any string 'N/A' or 'nan' with pandas NA\n",
    "df_links['Generation'] = df_links['Generation'].replace(['N/A', 'nan'], pd.NA).astype('string')\n",
    "df_links['Image URL'] = df_links['Image URL'].replace(['N/A', 'nan'], pd.NA).astype('string')\n",
    "\n",
    "#Filtering for the rows in the df_links that contain N/A (to be able to re-run this code withouth having to scrape all of them again)\n",
    "missing_data_df = df_links[df_links['Generation'].isna() | df_links['Image URL'].isna()]\n",
    "total_missing = len(missing_data_df)\n",
    "print(f\"üîé Found {total_missing} Pok√©mon entries with missing data.\")\n",
    "\n",
    "#How many to scrape\n",
    "try:\n",
    "    to_scrape = int(input(f\"How many would you like to scrape (max number {total_missing})?\"))\n",
    "    if to_scrape > total_missing or to_scrape < 1:\n",
    "        print (\"‚ùå Invalid number, exiting.\")\n",
    "        exit()\n",
    "        \n",
    "except ValueError:\n",
    "    print(\"‚ùå Invalid input. Must be a number.\")\n",
    "    exit()\n",
    "\n",
    "#Slicing the data to scrape to match the requested number\n",
    "missing_data_df = missing_data_df.iloc[:to_scrape]\n",
    "\n",
    "#Loop through the missing rows\n",
    "for idx, row in missing_data_df.iterrows():\n",
    "    dex = row['Dex']\n",
    "    name = row['Name']\n",
    "    poke_url = row['poke_links']\n",
    "    \n",
    "    try:\n",
    "        req_ep = Request(poke_url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        html = urlopen(req_ep).read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        #Finding the div container for the image\n",
    "        image_container = soup.find('div', class_='grid-col span-md-6 span-lg-4 text-center')\n",
    "\n",
    "        #Finding the <a> or <img> tag for the image url\n",
    "        img_tag = image_container.find('a', rel='lightbox')\n",
    "        if img_tag is None:\n",
    "            img_tag = image_container.find('img')\n",
    "            img_url = img_tag['src']\n",
    "        else:\n",
    "            img_url = img_tag['href'] if img_tag else 'N/A'\n",
    "\n",
    "        #Finding the Generation\n",
    "        gen_abbr = soup.find('abbr', title=True)\n",
    "        gen_text = gen_abbr.text.split() if gen_abbr else 'Unknown' #spliting to only have the number of the generation\n",
    "\n",
    "        #Update the DataFrame cells at this row index\n",
    "        df_links.at[idx, 'Generation'] = gen_text[1]\n",
    "        df_links.at[idx, 'Image URL'] = img_url\n",
    "        print(f\"‚úÖ Retrived= {name} | Generation: {gen_text[1]} | Img: {img_url}\")\n",
    "\n",
    "    except Exception as e: #for an unexpected error\n",
    "        print(f\"‚ùå Error with {pokemon} at {poke_url}: {e}\")\n",
    "    \n",
    "    time.sleep(2) #To pause for 2 seconds before the next request to not overload the server, and following the robots.txt of the site\n",
    "    \n",
    "#Updating the CSV file with the new data\n",
    "df_links.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
